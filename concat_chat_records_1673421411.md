0. 好名字可以让你的朋友更好地记住你 : 大佬们，针对不平衡的训练样本，0:1 差不多是10:1，我用random undersample取一部分label为0的样本出来训练，有没有办法在剩下的里面再抽一部分出来训练呀

1. 好名字可以让你的朋友更好地记住你 : 是不是那啥bootstrap

2. Jaspar安 : 有个问题 真实业务场景中 是也不平衡吗

3. Jaspar安 : 如果也不平衡且比例一致 说实话我不建议平衡样本

4. 好名字可以让你的朋友更好地记住你 : 对啊

5. Jaspar安 : 当然 抛砖引玉哈 希望大佬出来解答下

6. 好名字可以让你的朋友更好地记住你 : 可是那样训练结果不是有偏的么

7. 好名字可以让你的朋友更好地记住你 : 全预测成0

8. Jaspar安 : 比如硬币正面概率90% 背面10% 预测下一次正面的概率 你还需要把样本平衡吗

9. 宏 : 训练完模型可以输出概率，根据概率排序，然后自己定0，1的切分点

10. 好名字可以让你的朋友更好地记住你 : 要吧，如果评价标准是auc，他全预测成正面的auc高，他就会一直这样训练下去

11. 宏 : 正负样本不均衡，就是这样的

12. 好名字可以让你的朋友更好地记住你 : 我现在放的切分点事0.5

13. 好名字可以让你的朋友更好地记住你 : 那我试试

14. Jaspar安 : 是的 那他预测对了呀 往预测对的方向继续预测好像也没毛病？

15. 好名字可以让你的朋友更好地记住你 : 我怕他不预测负样本了

16. 宏 : 一般来说，根据业务目标去灵活使用模型

17. 宏 : 比如说你这个模型的目的是做推荐，确定了推荐的数量之后，根据排序选这个量的人群就好了

18. 宏 : 也不用去预测0，1

19. 好名字可以让你的朋友更好地记住你 : 可是我不确定这个数量要怎么办呢

20. Jaspar安 : 期望

21. 宏 : 用预测的概率，和实际的0，1，做分层

22. 宏 : 给出累计的1的概率

23. 宏 : 然后让运营看，配合运营测试

24. Jaspar安 : 阈值切分本身就是出现概率吗？

25. Jaspar安 : 我一直这么理解 不知道理解的对不对

26. 好名字可以让你的朋友更好地记住你 : 我试试看stratified sampling分层抽样

27. 宏 : 我没看懂，不过好像是累计概率

28. Jaspar安 : 阈值切分本身就是切分某个概率以上为真一下为假 或者反过来？

29. 宏 : 对

30. 好名字可以让你的朋友更好地记住你 : 对

31. 顶级炼铜士-darkfire : 你的样本有没有时序或者连续性的属性。数据本身的唯独还是指标唯独

32. 顶级炼铜士-darkfire : 他这个问题没有数据背景。很笼统的说数据不平衡问题

33. 顶级炼铜士-darkfire : 维度，打错了。手机打字，不方便

34. 好名字可以让你的朋友更好地记住你 : 背景其实就类似网上很火的那个信用卡违约

35. 好名字可以让你的朋友更好地记住你 : 违约的打1，没违约的打0

36. 顶级炼铜士-darkfire : 没做过，不知道

37. 饼干哥哥🍪 : 我试过 不平衡的数据集 抽样搞平衡

38. 饼干哥哥🍪 : 结果不太对

39. 好名字可以让你的朋友更好地记住你 : 是吧

40. 饼干哥哥🍪 : 有个函数可以拟合出一些数据来搞平衡

41. 好名字可以让你的朋友更好地记住你 : SMOTE

42. 顶级炼铜士-darkfire : 首先，这个是你材料的背景。其次，你所说的是说这个数据是原始数据，不是颗粒度数据。这个我收到了。

43. 顶级炼铜士-darkfire : 我手机打字，有点慢，等等哈

44. 好名字可以让你的朋友更好地记住你 : 现在我尝试了平衡样本，感觉预测到1有点偏多，不平衡样本，预测到0偏多

45. 顶级炼铜士-darkfire : 其次，你使用了什么模型，模型本身会不会因为数据类型的不均匀而发生改变。这个我也不知道。我以下情况你模型会因为数据样本不均匀导致精度缺失来说

46. 好名字可以让你的朋友更好地记住你 : 我暂时是用的xgboost

47. 好名字可以让你的朋友更好地记住你 : xgboost应该不用对特征进行normalize吧

48. 顶级炼铜士-darkfire : 我没记错的话，官方是有建议的

49. 宏 : 不用

50. 顶级炼铜士-darkfire : 好像有个参数来着

51. 好名字可以让你的朋友更好地记住你 : 是关于normalize还是关于平衡样本呢？

52. 顶级炼铜士-darkfire : 本身数模型就是这样[捂脸]数据质量决定模型优劣

53. 顶级炼铜士-darkfire : 树

54. 宏 : 一般来说，大样本下，样本抽样是不增加信息的，也就是说模型学不到新的东西，这种情况下，是不改变排序性。你模型的评价指标不就是auc吗，衡量排序性的指标。

55. 顶级炼铜士-darkfire : 随机抽样不会导致发生改变。

56. 顶级炼铜士-darkfire : 我个人的建议就是，像这样，直接模型融合进行学习。@好名字-坡县-游戏or待业 

57. 好名字可以让你的朋友更好地记住你 : xgboost融合lgb或者catboost么

58. 饼干哥哥🍪 : 合理 多模型融合能提高效果

59. 好名字可以让你的朋友更好地记住你 : 有什么好建议呢

60. 好名字可以让你的朋友更好地记住你 : 可是我平衡样本以后误判变多了诶

61. 顶级炼铜士-darkfire : 没有，反正我是不建议平衡，平衡是迫于无奈下，没有数据的操作。极限操作。我个人理解

62. 好名字可以让你的朋友更好地记住你 : 这样么

63. 宏 : 统计学上一般用ks达到最大作为切分点，就是累计1和累计0概率差值的最大值，在这个点上，理论上对0，1区分是最好的。但在实际使用过程中，可能要配合测试，要跟着运营的计划走，所以我建议就把输出的概率作为结果先存着。

64. 宏 : 好有个小妙招，测试尽量别那么大数据量，越小显得你这个模型越好。

65. 宏 : 至少给运营的印象是这样

